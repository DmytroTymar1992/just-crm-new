# ai_helper/tasks.py
from celery import shared_task
from django.apps import apps
from django.db import transaction
from django.utils import timezone
import logging
from .openai_service import suggest_task
from .models import AiSuggestion
from django.conf import settings
from calls.models import Call
import json
from openai import OpenAI
from channels.layers import get_channel_layer
from asgiref.sync import async_to_sync


Interaction = apps.get_model("chats", "Interaction")
logger = logging.getLogger(__name__)

def load_result_options_from_file(path='ai_helper/data/call_results_list.txt'):
    try:
        with open(path, encoding='utf-8') as f:
            lines = [line.strip() for line in f if line.strip() and not line.startswith("#")]
        return lines
    except Exception as e:
        logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤: {e}", exc_info=True)
        return []

def build_gpt_prompt(transcript):
    result_options = load_result_options_from_file()
    options_text = "\n".join(result_options)

    system_prompt = (
        "–¢–∏ ‚Äî CRM-–∞—Å–∏—Å—Ç–µ–Ω—Ç. –¢–æ–±—ñ –Ω–∞–¥–∞—î—Ç—å—Å—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –¥–∑–≤—ñ–Ω–∫–∞ –∑ –∫–ª—ñ—î–Ω—Ç–æ–º. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî:\n"
        "1. –í–∏–∑–Ω–∞—á–∏—Ç–∏ *—Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–∑–≤—ñ–Ω–∫–∞* ‚Äî –æ–¥–Ω—É —Ñ—Ä–∞–∑—É –∑—ñ —Å–ø–∏—Å–∫—É –Ω–∏–∂—á–µ.\n"
        "2. –°—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å —Ä–æ–∑–º–æ–≤–∏ (1-3 —Ä–µ—á–µ–Ω–Ω—è).\n\n"
        "üí° –û–±–æ–≤‚Äô—è–∑–∫–æ–≤–æ –ø–æ–≤–µ—Ä–Ω–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —É **—Ç–æ—á–Ω–æ–º—É JSON-—Ñ–æ—Ä–º–∞—Ç—ñ**:\n"
        "{ \"result\": \"...\", \"description\": \"...\" }\n\n"
        "–ù–µ –ø–∏—à–∏ –Ω—ñ—á–æ–≥–æ –ø–æ–∑–∞ –º–µ–∂–∞–º–∏ JSON. –†–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—î –±—É—Ç–∏ –æ–¥–Ω—ñ—î—é —Ñ—Ä–∞–∑–æ—é –∑ —Ü—å–æ–≥–æ —Å–ø–∏—Å–∫—É:\n"
        f"{options_text}"
    )

    user_prompt = f"""–û—Å—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è —Ä–æ–∑–º–æ–≤–∏:
{transcript}

–í–∏–∫–æ–Ω–∞–π —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—é –≤–∏—â–µ.
"""

    return system_prompt, user_prompt

@shared_task
def analyze_transcription_result(call_id):
    try:
        call = Call.objects.get(pk=call_id)
        if not call.transcription:
            logger.warning(f"Call {call_id} has no transcription.")
            return

        system_prompt, user_prompt = build_gpt_prompt(call.transcription)

        client = OpenAI(api_key=settings.OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.3,
            max_tokens=300,
        )
        raw = response.choices[0].message.content.strip()
        logger.debug(f"Raw GPT response for call {call_id}: {raw}")

        parsed = json.loads(raw)

        call.result = parsed.get("result")
        call.description = parsed.get("description")
        call.save()
        logger.info(f"Saved GPT result for call {call_id}: {call.result}")

        # üîÑ WebSocket: –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
        channel_layer = get_channel_layer()
        async_to_sync(channel_layer.group_send)(
            f"chat_{call.interaction.chat_id}",
            {
                "type": "open_call_result_modal",
                "call_id": call.id,
                "result": call.result,
                "description": call.description or "",
                "loading": False
            },
        )
        logger.info(f"Sent WebSocket update for call {call.id} with GPT result.")

    except json.JSONDecodeError:
        logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ JSON –≤—ñ–¥ GPT –¥–ª—è call {call_id}", exc_info=True)
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ GPT –∞–Ω–∞–ª—ñ–∑—É call {call_id}: {e}", exc_info=True)




@shared_task(bind=True, max_retries=3, default_retry_delay=30)
def generate_task_for_interaction(self, interaction_id: int):
    try:
        interaction = (
            Interaction.objects
            .select_related("chat", "contact", "user")
            .get(pk=interaction_id)
        )

        # 1. –¥—ñ—Å—Ç–∞—î–º–æ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—é –≤—ñ–¥ GPT-4o
        data = suggest_task(interaction)          # {'type': ‚Ä¶, 'goal': ‚Ä¶, 'short_description': ‚Ä¶}

        # 2. –æ–¥–∏–Ω –∑–∞–ø–∏—Å –Ω–∞ —á–∞—Ç ‚Üí –æ–Ω–æ–≤–ª—é—î–º–æ –∞–±–æ —Å—Ç–≤–æ—Ä—é—î–º–æ
        with transaction.atomic():
            AiSuggestion.objects.update_or_create(
                chat=interaction.chat,            # –∫–ª—é—á (OneToOne primary_key)
                defaults={
                    "contact":           interaction.contact,
                    "user":              interaction.user,
                    "type":              data["type"],
                    "goal":              data["goal"],
                    "short_description": data["short_description"],
                    "updated_at":        timezone.now(),
                },
            )

    except Exception as exc:
        raise self.retry(exc=exc, countdown=60)
